\section{Facilities, Equipment, and Other Resources}
 

Physical Plant: The research group for the proposal is housed in the
SDSC building on the UCSD campus. The building provides sufficient
space for the entire team, including space for interns planned for the
project. The building co-locates the project team with a wide variety
of scientists, developers, and support staff who are pursuing similar
research agendas. The physical plant provides access to all essential
facilities for a project of this type: conference rooms,
teleconferencing facilities including the Access Grid, an
international resource for visual telecommunication, and the
SDSC/Calit2 Synthesis Center, a national resource for visually based
collaboration on research projects. This location will be ideal for
user and developer workshops. The Machine Room at SDSC has recently
expanded to allow both more floor space, power, and cooling capacity
to accommodate the computational resources needed by this project.

 

\subsection{High Perfomance Computers}

SDSC is a well established production facility with many computational
resources. Most recently, the SDSC has put into production the Triton
Resource, a High Performance cluster with 256 nodes, each containing 2
quad-core Intel 2.4 GHz processors and 24 GB memory; the machine
offers 20 TeraFlops peak performance. Small allocations of time are
made on this machine at no charge to SDSC researchers, and large time
allocations are made to SDSC researchers on a recharge basis (0.03 per
cpu hour). Other computational resources are available to the project
via the NSF national allocation process. Computational time is awarded
via a competitive application process, and development accounts are
provided on request on a recharge basis. Access is also available to
non-production servers where jobs can be deployed on experimental
architectures committing them to production.


The Triton Resource at the San Diego Supercomputer Center is a high
performance computing system supporting researchers at the University
of California. The Triton Resource consists of two subsystems: The
Triton Compute Cluster (TCC) and the Petascale Data Analysis Facility
(PDAF). Both are supported by a high performance parallel file system
and have connectivity to high bandwidth research networks.

The TCC is a 256-node Appro HyperGreen cluster. Each node contains
dual quad-core Intel Xeon 5500 (formerly code-named Nehalem)
processors running at 2.4 gigaHertz, and 24 gigabytes of main memory.
The nodes are interconnected with a 10 gigabit-per-second Myrinet
fabric. The TCC has a peak theoretical performance of 20 teraflops and
six terabytes of memory.

The PDAF is a unique data-intensive computing resource with one of the
largest main memory capacities of any publicly available system. The
PDAF comprises 28 Sun x4600M2 symmetric multiprocessing (SMP) nodes.
Each node contains eight quad-core AMD 8380 processors running at 2.5
gigaHertz. Twenty of the nodes have 256 gigabytes of main memory per
node and eight of the nodes have 512 gigabytes of main memory. The
PDAF nodes are interconnected with a 10 gigabit-per-second Myrinet
fabric. The PDAF has a peak theoretical performance of nine teraflops,
and nine terabytes of memory.

\subsection{IT Infrastructure}

The center also provides connectivity to the Internet via an internal
fiber optic network, with multiple vBNS network connections that can
carry approximately 2 Gbps in the aggregate, as well as connectivity
to Grid resources through the TeraGrid backbone (max throughput at 30
Gbps). The project will have access to the SDSC storage resource
broker (SRB), and the high performance storage system (HPSS) which
makes available to the user a 18 Petabytes of tape storage capacity.
This resource is available essentially for the cost of tapes. The
participants will also have the ability to apply for computational
cycles and online storage space through SDSC and TeraGrid allocation
services. It is important to note that despite the very significant
amount of on line storage space present at SDSC, our request for an 11
TB is storage device is not redundant with existing equipment because
it is meant to support the storage of private data for individuals
prior to publication. This kind of storage cannot be provided under a
national allocation protocol, because the data is not meant entirely
for public distribution: the individual users must have control over
what is shared and what is nto, and on what time scale.

 
The IT support infrastructure at SDSC provides 24/7 production level
support, and working day (8/5) help desk/user services support to
assist in resolving technical issues. This project will have access to
the full expertise and insitutional experience to support state of the
art computer equipment, including major servers, database storage
devices, personal desktop machines, and notebooks.

 

 

\subsection{Expertise}

Research expertise: SDSC has a staff of more than 400 scientists,
software developers, and support personnel. SDSC also sponsors several
major data projects in Biology, and several others in the geo- and
environmental sciences. Each of these projects is developing a
workbench area for its users. As a result, there is an "intellectual
capital" of nearly 50 persons who are currently engaged in the
development of cuttting edge resources for web based portals and data
distribution. This includes a body of 30 software engineers who are
creating production level tools to serve their respective communities.
This makes SDSC an ideal environment for the construction of the kind
of infrastructure resource we are proposing here.

 

Facilities used for the participants are accessible to participants
with disabilities.
