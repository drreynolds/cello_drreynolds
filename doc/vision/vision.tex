%0       1         2         3         4         5         6         7         8
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%=======================================================================
\documentclass[11pt]{article}
%=======================================================================

\include{include}

%=======================================================================

\begin{document}

%=======================================================================
\TITLE{\cello\ Vision and Scope Document \\
      \Large{\enzo: The Next Generation}}{James Bordner}{$Rev$}
%=======================================================================

%=======================================================================
\section{Problem Statement}
%=======================================================================

%-----------------------------------------------------------------------
\subsection{Project background}
%-----------------------------------------------------------------------


    The \cello\ Project\footnote{While the origin of the name
    ``\enzo'' has been lost in mist of time, the name ``\cello'' was
    derived from the computational term ``cell'', which is a synonym
    of the computational term ``zone'', which in turn is an anagram of
    ``enzo''.  Analogously, the \cello\ code will be derived from
    \enzo's code by rearranging it, modifying it, and, uh, sticking an
    ``o'' on the end.}  is designed to be the successor to
    \enzo.  \enzo\ was conceived in the early 1990's by
    Michael L.~Norman and Greg Bryan to be a multi-resolution
    astrophysics and cosmology application, implemented using
    structured (patch-based) adaptive mesh refinement (SAMR).  It
    incorporated a modified high-order Piecewise Parabolic Method
    (PPM) solver for hydrodynamics, and a Particle-Mesh (PM) method
    for dark matter dynamics.  So far in its 14 year lifetime, \enzo\
    simulations have led to important scientific contributions to the
    fields of astrophysics, cosmology, and turbulence.

    Greg Bryan began implementing \enzo\ in 1994.  He wrote it in C++
    with Fortran 77 computational kernels for speed, using primarily a
    procedural (structured) programming paradigm.  Initially he
    targeted shared memory platforms, and later switched to
    distributed memory platforms via the Message Passing Interface
    (MPI).

    Beginning around 2000, other developers began to modify \enzo\ in
    earnest. As an oversimplification, David Collins added MHD
    physics, Dan Reynolds added RHD physics, Alexei Kritsuk added
    turbulence-related modifications, Brian O'Shea updated star
    formation algorithms, Greg Bryan himself modified AMR algorithms
    to improve performance, and Robert Harkness continually made
    innumerable modifications related to data structures and disk IO.
    Robert in particular has greatly improved performance and scaling,
    and has almost single-handedly brought \enzo\ into the Terascale
    era.

    The software development strategy used has been very informal.
    \enzo\ was developed without any supporting documents, such as
    requirement specifications, design description, or test document.
    It was also written without any explicit coding standard, though
    the original author closely followed implicit coding guidelines,
    such as including uniform file header comment blocks, and using
    descriptive variable, function, and file names.  The original
    author also implemented many application tests to help ensure
    code correctness and solution accuracy.  

% Enzo is getting harder to develop
    The relaxed software development strategy used with \enzo,
    combined with the shift from single-person to multi-person
    development, have resulted in a rapid increase in \enzo's
    complexity.  This increased software complexity translates
    directly into increased difficulty in modifying and maintaining
    the code.  Furthermore, \enzo's relatively
    ``modification-resistant'' structured programming
    paradigm is a further hinderance to its continued
    development.
    
% pargraph: Enzo requires further development

% pargraph: Above two points motivate cello

    These two issues motivate the \cello\ Project.  While \enzo's
    developmont is still progressing vigorously, its software
    complexity and structure are making development increasingly slow
    and difficult.  Yet large-scale and pervasive modifications are
    still needed, both to increase the physics capabilities required
    by its users, and to improve the performance and scaling to bring
    \enzo\ from the Terascale Era into the Petascale Era.  By
    redeveloping \enzo's functionality for the same user base with 1)
    a more structured software development strategy, 2) using the
    relatively ``modification-friendly'' object oriented programming
    paradigm, and 3) with more flexible and scalable
    parallel data structures, we can specifically target the hierarchical and
    massive parallelism and deep memory hierarchies of Petascale
    platforms \textit{a priori}.

% Future relationship between Enzo and Cello

    We believe that \enzo\ is the best solution in the short term,
    whereas \cello\ is the best solution in the long term.  To use a
    computational analogy, \enzo\ is like a short but relatively slow
    vector operation, whereas \cello\ is like a long but relatively
    fast vector operation.  Like filling a long vector pipeline,
    \cello\ will require some time before it will start producing
    scientific results; but once it is operational, \cello's improved
    modifyability and scalability will eventually result in \cello\
    users producing scientific results more frequently than \enzo\
    users.  To optimize scientific results in both the short and long
    term, we believe it makes sense to continue development with
    \enzo\ while concurrently begining development on \cello.
  
%-----------------------------------------------------------------------
\subsection{Stakeholders}
%-----------------------------------------------------------------------

\subsubsection{Executives}

    To clarify roles among stakeholders---and for fun, if not
    profit---we assign ``effective'' titles to executives:

\begin{description}
%
    \item[CEO:]   Prof.~Michael L.~Norman, founder of the Laboratory for
    Computational Astrophysics, will be the effective \textit{Chief Executive Officer}.
%
    \item[CSO: ] Prof.~Greg Bryan, original author of \enzo, will be the
    effective \textit{Chief Science Officer}.
%
    \item[CTO: ] Dr.~Robert Harkness, expert in both \enzo\ and supercomputer
    technology, will be the effective \textit{Chief Technology
    Officer}.
%
\end{description}

   Their roles include identifying any potential roadblocks that may
   arise, and keep the general direction of the project focused and on
   track.

\subsubsection{Developers}

   Due to the nature of academic software development, the development
   team is expected to change throughout the course of the project as
   students graduate and leave the development team and new students
   join.  Below is the initial list of developers and their main roles:

\begin{itemize}
    \item Dr.~James Bordner (\cello\ Development Leader, high-level design, data structures, documentation)
    \item Dr.~Robert Harkness (low-level design, performance and scaling specialist)
    \item Rick Wagner (unit testing and analysis specialist)
    \item Dr.~Alexei Kritsuk (hydrodynamics and turbulence specialist)
    \item David Collins (MHD specialist)
    \item Dr.~Dan Reynolds (RHD specialist)
    \item Prof.~Brian O'Shea (star formation specialist)
    \item Dr.~Paschal Paschos (RHD, chemistry and cooling specialist)
    \item Stephen Skory (quality assurance and application testing)
\end{itemize}

%-----------------------------------------------------------------------
\subsection{Users}
%-----------------------------------------------------------------------


    There are several ways of partitioning users into groups, each of
    which exposes specific requirements of the \cello\ design and
    implementation.


    One partitioning of users is into core users, collaborators, and
    community users.
%
    \textit{Core users} are the scientists and graduate students in
    the Laboratory for Computational Astrophysics.  Most core users
    will also participate in development of \cello, and most
    developers will be core users.  Core users include Norman,
    Kritsuk, Padoan, Harkness, Collins, Paschos, Wagner, and Skory.
%
    \textit{Collaborative users} include all scientists not currently
    in the Laboratory for Computational Astrophysics, but who will use
    \cello\ and coauthor papers with current LCA members.
    Collaborative users may include Tom Abel, John Hayes, Bryan
    O'Shea, Dan Reynolds, and Dan Whalen.
%
    \textit{Community users} are all remaining users.  We expect that
    \cello\ functionality will be driven primarily by the needs of the
    core and collaborative users, since they are fairly representative
    of general community users.  However, \cello\ will be designed
    specifically to be a community code, so must meet the needs of
    community users as a whole.

    Another way to partition users is into users that will run \cello\
    as provided, and users that will modify \cello\ for their own
    particular needs.  For example, the latter group may want to add
    new physics support to \cello, or may want to use \cello\ to help
    develop their own numerical methods.  The existence of this second
    group will have an important bearing on the design of \cello.
    Specifically, \cello\ should be modular and easy to modify by the
    non-core developers as well as core developers.  In particular, it
    should be straightforward to add new physics capabilities, and to
    add new algorithms for existing methods.  This includes making it
    easy to add new input parameters for controlling new or modified
    numerical methods or data structures in \cello.

    Yet another partitioning of users is into research scientists and
    graduate students.  Scientists will typically use \cello\ to
    perform large-scale computational experiments that will increase
    the global scientific knowledge base, whereas students may be
    using \cello\ at least partially to learn about computational
    astrophysics and cosmology, and to advance their own research.
    Scientists are likely to prefer deep control of the methods,
    physics, parallel data structures, and large-scale detailed
    analysis and visualization, with power and flexibility taking
    precidence over ease of use.  Students on the other hand are
    likely to prefer to be able to concentrate on the science, with
    ease-of-use taking precidence over having to worry about detailed
    computational technology issues that only serve to complicate and
    interfere with the learning process.  \cello\ should therefore
    support both deep and flexible control over physics, algorithms,
    and analysis, while simultaneously be easy to set up problems, and
    easy to run, analyse, and visualize the results.
    

%-----------------------------------------------------------------------
\subsection{Risks}
%-----------------------------------------------------------------------

   All software development projects have risks.  Things can and will
   happen that lead to deviations from the original plan, so it is
   important to identify potential risks early, evaluate their
   probabilities and potential effects on the project, and formulate
   contingency plans ahead of time.  Below is a list of some possible
   risks:

    \begin{itemize} 
%
    \item Uncertain future of development team membership,
    e.g.~graduate students graduating and new students joining.
%
    \item Uneven capabilities of development team members, including
    software development processes, computer languages, parallel
    programming, and numerical methods.
%
    \item Uncertain future parallel platform characteristics,
    including GPU's, many-core processors, shared/distributed memory
    configurations, vector processing, and overall architecture
    variability and complexity.
%
    \item Overdependency on a single platform, e.g.~IBM Blue Waters.
%
    \item Political pressure to use specific software languages, frameworks, or
    libraries, e.g.~CHARM++ or UPC, even if they may not be in the
    project's best interest.
%
    \item Resistance among \cello\ developers to use specific software
    languages, frameworks, or libraries, even if they may be in the
    project's best interest.
%
    \item Discontinued or uncertain future development of dependent software
    languages, frameworks, or libraries that are used.
%
    \item Unforseen new parallel programming developments, e.g.~a new
    widely-accepted parallel language, or a new parallel programming
    paradigm.
%
    \item Uncertain future usability and support of parallel
    programming infrastructures, e.g.~MPI or OpenMP.
%
\end{itemize}


%-----------------------------------------------------------------------
\subsection{Assumptions}
%-----------------------------------------------------------------------

    % This is the list of assumptions that the stakeholders, users, or
    % project team have made. Often, these assumptions are generated
    % during a Wideband Delphi estimation session (see Chapter 3). If
    % Wideband Delphi is being used, the rest of the vision and scope
    % document should be ready before the Delphi meeting and used as the
    % basis for estimation. The assumptions generated during the
    % estimation kickoff meeting should then be reviewed, and any
    % nontechnical assumptions should be copied into this
    % section. (Technical assumptions---meaning assumptions that affect
    % the design and development but not the scope of the
    % project---should not be included in this document. The estimate
    % results will still contain a record of these assumptions, but they
    % are not useful for this particular audience.)

%=======================================================================
\section{Vision of the Solution}
%=======================================================================

%-----------------------------------------------------------------------
\subsection{Vision statement}
%-----------------------------------------------------------------------

    % The goal of the vision statement is to describe what the project
    % is expected to accomplish. It should explain what the purpose of
    % the project is. This should be a compelling reason, a solid
    % justification for spending time, money, and resources on the
    % project. The best time to write the vision statement is after
    % talking to the stakeholders and users and writing down their
    % needs; by this time, a concrete understanding of the project
    % should be starting to jell.

%   Cello is the next generation of Enzo

    The purpose of the \cello\ project is to produce the next
    generation of the open source software application \enzo\ for
    high-performance computational astrophysics and cosmology.  It
    will be used both as a testbed for experimenting with new software
    organization, parallelization, distributed data structure,
    algorithm, and implementation techniques, as well as for enabling
    cutting-edge astrophysics and cosmological science simulations on
    the largest parallel high performance computers available.
    Objectives are to reliably provide high-quality multi-resolution
    numerical solutions, computed by distributing the workload
    efficiently across $10^5$ to $10^6$ computational units, while
    maintaining a high level of utilization of available computational
    resources.

%   Primary goal

    But the primary goal of \cello\ is to increase the ability of
    scientists and students
    to perform numerical experiments of high scientific worth.
%   Characteristics supporting the primary goal
    To support the primary goal of improved science, we recognize that
    \cello\ must improve on a range of characteristics compared to
    \enzo, including 
%
    improved parallel scalability,
    improved modifyability, 
    and improved ease of use.

%   Scalable

    \textbf{Scalable.} \cello\ must be able to run efficiently on
    Petascale architectures.  This means being able to solve the
    largest problems that can possibly fit in available Petascale
    architectures.  Although \enzo's ``unigrid'' (uniform resolution)
    mode of operation has shown high scalability, its ``AMR''
    (multi-resolution) mode has not.  The existing adaptive mesh
    refinement method and implementation has limitations related to
    load balancing and non-scalable memory requirements.  While
    independent but coordinated efforts are currently underway to
    improve the scaling of \enzo---in particular Robert Harkness is
    adding support for hybrid MPI / OpenMP, and James Bordner is
    refactoring the AMR data structure to reduce its memory
    requirement---these improvements are still limited by the use of
    the structured adaptive mesh refinement approach.  While details
    of \cello\ data structures are beyond the scope of this document,
    the planned AMR methodology will be reengineered, and even the
    unigrid implementation will be much improved in terms of both
    parallel scaling and computational efficiency.

%   Modifyable

    \textbf{Modifyable.} \enzo\ code is tightly coupled, repetitious,
    complicated, difficult to read, difficult to understand, and
    difficult to modify.  Yet \enzo\ is an application that must be
    modified continually, both to be able to run effectively on
    rapidly evolving supercomputer platforms, and also to implement
    newly developed and improved numerical methods.  When multiple
    developers continually modify a software application designed
    using the structured programming paradigm, code complexity
    inevitably grows.  The design of \cello\ will improve this by
    using an object-oriented design and a less casual software
    development approach.  \cello's complexity will be able to be kept
    much smaller than \enzo's for the same functionality.
    Equivalently, \cello\ will be able to have much greater
    functionality for the same amount of software complexity.  Both
    the improved software development techniques and object-oriented design
    approach, \cello\ will be much easier to maintain, modify, and enhance.

%     Although \enzo\ must be continually modified, it is not specificially
%     designed to be modified.  It was written primarily using the
%     structured programming paradigm, which is known to be effective
%     for designing and implementing large-scale applications, but is
%     not ideal for subsequent redesign and modification.  As \enzo\ has
%     been repeatedly modified by successive researchers and students,
%     its complexity has increased rapidly, in particular much faster
%     than the inherent complexity of the underlying functionality being
%     implemented.

%     To maintain control over how effectively \cello\ can be modified
%     and enhanced to keep up with rapidly changing supercomputer
%     platform characteristics and new physics capabilities, we also
%     wish to keep \cello\ not overly-dependent on external libraries.
%     Some libraries, such as HDF5 and MPI, are of course indispensible.
%     But using some other libraries, frameworks, or languages, may lead to 
%     \cello\ being a ``slave'' to another software group.


%   Usable


    \textbf{Useable.}  The user interface, both input and output, will
    be improved in \cello.  For input, \enzo\ currently uses a large
    ``flat'' list of input parameters.  Because they are not organized
    explicitly into sections, it can be difficult for users to read,
    write, and understand parameter files.
%
    Also, \enzo\ parameters have limited expressibility---each
    parameter is typically an integer with a small number of valid
    values.
%
    The limited input file grammar inherently limits the power of
    \enzo\ itself.  For example, input control is not sufficiently
    powerful to define a new test problem that is not already
    implemented explicitly in code: running a new test problem in
    \enzo\ requires enhancing the \enzo\ codebase.  \cello\ will thus
    be much easier to use, both due to improved organization of input
    parameters, and due to increased power of expression of the input
    files.  For output, \cello\ will also be more ``user-friendly''.
    It will include automatic generation of web pages to serve as both
    a way to monitor a running simulation, and to easily share
    information about simulations with collaborators.  Data collected
    will include information related to the progress of the
    simulation, performance measurements, and inline analysis and
    visualization.

%     Input files will support a much more powerful grammar to allow for
%     much greater control of \cello.  \enzo\ uses a flat list of input
%     parameters of simple type, which has limited scalability in terms
%     of expressive range.

%     \cello\ will use a hierarchical list of parameters, and will
%     permit more complex types, such as mathematical expressions and
%     composite spacial/temporal subregions.  While extra code will be
%     required to parse and interpret the input files, the code in
%     \enzo\ used for defining and initializing specific problem types
%     will not be required, since the input file grammar will be
%     sufficiently powerful to implement them without problem-specific
%     code.  Overall, this may even result in less code, while
%     supporting a much greater scope of problem setup without requiring
%     modifying the code.


%-----------------------------------------------------------------------
\subsection{List of features}
%-----------------------------------------------------------------------

    % This section contains a list of features. A feature is as a
    % cohesive area of the software that fulfills a specific need by
    % providing a set of services or capabilities. Any software
    % package---in fact, any engineered product---can be broken down
    % into features. The project manager can choose the number of
    % features in the vision and scope document by changing the level of
    % detail or granularity of each feature, and by combining multiple
    % features into a single one. Sometimes those features are small
    % ("screw-top cap," "holds one liter of liquid"); sometimes they are
    % big ("four-wheel drive," "seats seven passengers"). It is useful
    % to describe a product in about 10 features in the vision and scope
    % document , because this usually yields a level of complexity that
    % most people reading it are comfortable with. Adding too many
    % features will overwhelm most readers.

    % Each feature should be listed in a separate paragraph or bullet
    % point. It should be given a name, followed by a description of the
    % functionality that it provides. This description does not need to
    % be detailed; it can simply be a few sentences that give a general
    % explanation of the feature. However, if there is more information
    % that a stakeholder or project team member feels should be
    % included, it is important to include that information. For
    % example, it is sometimes useful to include a use case (see Chapter
    % 6), as long as it is written in such a way that all of the
    % stakeholders can read and understand it.

%
%   Physics
%   Methods
%   Analysis and visualization
%   User interface
%   Parallelism
%   Data structures
%
    %-----------------------------------------------------------------------
    \subsubsection{Physics capabilities}

    The initial scope of physics capabilities of \cello\ will be the
    same as \enzo: representations of baryonic and dark matter,
    hydrodynamics, self-gravity, multi-species chemistry, radiative
    cooling, cosmological expansion, star formation,
    magnetohydrodynamics, and radiation transfer.  Additional physics
    capabilities are expected to be implemented during \cello's
    lifetime.

    %-----------------------------------------------------------------------
    \subsubsection{Numerical methods}

    Numerical methods will be a combination of existing numerical
    methods taken from \enzo, and new and improved methods that have
    been developed more recently.  For hydrodynamics, both the
    modified Piecewise Parabolic Method (PPM) solver in \enzo\ will be
    implemented, as well as a new non-operator split variation to
    improve asymmetry effects, and PPML for MHD.  For Dark matter
    dynamics, \enzo's Particle-Mesh (PM) method will be used.  For
    self-gravity, linear solvers will be used on the entire mesh
    hierarchy to solve the Poisson equation self-consistenty.  Unigrid
    self-gravity can be computed efficiently in parallel using 3D
    FFT's for periodic boundary conditions, or parallel multigrid
    methods for non-periodic boundary conditions.  For AMR, initially
    a FAC-type method will be used, though a method of local
    corrections (MLC) method may additionally be implemented, which
    may have better parallel efficiency due to reduced communication
    requirements.

    %-----------------------------------------------------------------------
    \subsubsection{Parallelism} 

% Hierarchical parallel tasks

    To take advantage of the hierarchical parallel nature of modern
    supercomputers, \cello\ will directly support multiple levels of
    parallelization in its methods and data structures.  This will
    include the coarse-grain parallelism to concurrently run
    simulations in an ensemble at the node or supernode level,
    medium-grain parallelism to evolve grid patches or particle groups
    of a simulation concurrently across a distributed memory subsystem
    at the node or socket level, and fine-grain parallelism to evolve
    grid cells within grid patches or particles within a group using
    shared-memory parallelism at the socket or core level.

% Hierarchical parallel technologies

    This parallelization will be modularized (as much as feasible
    using object-oriented approach) to improve flexibility in choosing
    the best method(s) of parallelization for a given problem on a
    given parallel platform.  MPI-1 (two-sided), MPI-2 (one-sided),
    OpenMP, and possibly UPC support will be included, as well as
    flexibility in choosing hybrid schemes such as MPI + OpenMP, or
    MPI + UPC.  Other schemes based on shared memory array libraries
    or POSIX pthreads may also be considered.  Parallelization methods
    will be primarily data parallelism, supporting both distributed
    memory and shared memory in isolation or combination.  Support for
    collaberative (functional) parallelism and pipelining will also be
    considered, as will be GPU-based vector programming, depending
    on how hardware platforms and middleware evolves.

%  Load balancing

    Multiple levels of parallel tasks will be load balanced using
    hierarchical dynamic load balancing algorithms.  Load balancing
    schemes will use dynamically measured performance data gathered by
    the running simulation to make load balancing decisions, and will
    allow flexibility in optimizing the parallel distribution of
    computation, memory storage, or a combination of both.  Combining
    1) scalable methods, 2) scalable and efficient AMR data
    structures, 3) hierarchical parallelization schemes, and 4)
    hierarchical load balancing algorithms, are expected to lead to an
    application with overall high parallel efficiency and scalability
    on platforms with a large amount of parallelism organized into
    several hierarchical groups.

%   Task scheduling (reduced synchronization)

    %-----------------------------------------------------------------------
    \subsubsection{Data structures}

    As with \enzo, computations will be performed at multiple spacial
    and temporal resolutions using some form of adaptive mesh
    refinement (AMR).  This will permit the physics modules to capture
    the full range of scales of interest, but without excessive
    computation and memory storage.  However, the AMR approach and
    data structures will be totally redesigned and reimplemented.
    Compared to \enzo, the new design will include improved load
    balancing, improved data locality, reduced memory usage, improved
    memory scaling, support for hierarchical parallelism (e.g.~MPI +
    OpenMP), control of task sizes at different parallelization
    levels, and more efficient use of the memory hierarchy through
    array blocking and padding techniques.  Additionally, the
    software's object-oriented design will reduce overall code
    complexity and increase the flexibility and modifyability of the
    parallel distributed data structure implementations.

    % patches may be distributed (MPI), threaded (OMP), and blocked (cache)

    The properties of individual grid patches, and details of how
    scalar and vector fields are stored within grid patches, will be
    flexible to permit optimizing the use of node and processor/core
    parallelism, as well as deep memory/cache hierarchies.  This
    includes hierarchical subblocking of grid patch arrays to optimize
    MPI task size, OMP thread task size, and cache block size and
    configuration.  Additionally, arrays may be padded to reduce cache
    thrashing effects for low-associativity caches, and may be
    interleaved to improve data locality (or to make it easier to
    interface with existing computational kernels that use interleaved
    array data, e.g.~the PPML MHD solver implementation).  These
    capabilities, together with efficient methods and implementation
    of computations, are expected to lead to high single-thread
    computational efficiency and data movement through memory/cache
    hierarchies.

    % Octree to improve load balancing and data structure complexity
    % patches to maintain efficiency
    % variable patch size to reduce octree overhead
    %   (this is new)


    % Particles


%-----------------------------------------------------------------------
\subsection{Scope of phased release}
%-----------------------------------------------------------------------

    % Sometimes software projects are released in phases: a version of
    % the software with some subset of the features is released first,
    % and a newer, more complete version is released later. This section
    % describes the plan for a phased release, if that approach is to be
    % taken.

    % This is useful when there is an important deadline for the
    % software, but developing the entire software project by that
    % deadline would be unrealistic. The most common way to compromise
    % on this release date is to divide the features into two or more
    % releases. In that case, this section should identify specifically
    % when those versions will be released, and which features will be
    % included in each version. It's reasonable to divide one feature up
    % between two releases, as long as it is made clear exactly how that
    % will happen.

    % If a project manager needs to release a project in phases, it is
    % critical that the project team be consulted. Some features are
    % much more difficult to divide than others, and the engineers might
    % see dependencies between features that are not clear to the
    % stakeholders and project manager. After the phased release plan is
    % written down and agreed upon, the project team should always be
    % asked to re-estimate the effort and a new project plan should be
    % generated (see below). This will ensure that the phased release is
    % feasible and compatible with the organization's priorities.

\begin{description}
\item[Year 1: ]\
\begin{itemize}
\item Data structures: unigrid + particles
\item Physics: hydrodynamics, MHD, self-gravity
\item Methods: PPM, PPML, 3DFFT
\end{itemize}

\item[Year 2: ] 
\begin{itemize}
\item Data structures: AMR + particles
\item Physics: ???
\item Methods: FAC
\end{itemize}

\item[Year 3: ]
\begin{itemize}
\item Data structures: unigrid
\item Physics: ???
\item Methods: MLC
\end{itemize}
\end{description}
%-----------------------------------------------------------------------
\subsection{Features that will not be developed}
%-----------------------------------------------------------------------


    % Features are often left out of a project on purpose. When a
    % feature is explicitly left out of the software, it should be added
    % to this section to tell the reader that a decision was made to
    % exclude it. For example, one way to handle an unrealistic deadline
    % is by removing one or more features from the software, in which
    % case the removed features should be moved into this section. The
    % reason these features should be moved rather than deleted from the
    % document is that otherwise, readers might assume that they were
    % overlooked and bring them up in a review. This is especially
    % important during the review of the document because it allows
    % everyone to agree on the exclusion of the feature (or object to
    % it).

\end{document}

%==================================================================
