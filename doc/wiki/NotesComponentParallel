([NotesComponentMonitor Monitor] < [NotesComponents index] > [NotesComponentParameters Parameters])

[[TOC]]

= Parallel Component =

The `Parallel` component provides services to aid in the efficient data distribution and dynamic load balancing
on hierarchical parallel platforms.  This is done using one or more parallelization languages or libraries, including MPI, OpenMP, or UPC.

The `Parallel` component keeps track of data assigned to processors in a hierarchical manner.  This helps to both efficiently map data to the physical hardware, and to reduce the amount of storage or communication required for load balancing.

The main data structure is a tree with nodes corresponding to threads or processes, and how they are organized into higher levels (e.g. cpu's, compute nodes, supernodes, etc.)  The actual tree is stored in a distributed manner, with tree nodes stored only for level entities (cpu, compute node, etc.) that  contain the process.

Communicators are available at each level of the hierarchy to facilitate efficient communication within a cpu, node, etc.  By default, communicators involve one tree node per level, all tree nodes in a level are in a communicator.  For example, in a process hierarchy of 4 compute nodes (level 0), 32 cpu's per compute node (level ), and 8 cores per cpu (level 2), each process would be in one communicator of size 4 at level 0, one of size 32 at level 1, and one of size 8 at level 2.

By default, communicators link corresponding compute components , for example, all like-processes in coarser hierarchy levels share a communicator with their counterpart in other .  To provide some flexibility to reduce hotspots in the hardware network, these can be remapped dynamically to "load balance" communication.
  
=== Related Classes ===

To implement `Parallel`, other related classes are used to share implementation responsibilities. These classes are described in separate pages.

 * [NotesComponentParallelTask Task] The `Task` class is used to control different distributed entities.  It maintains information such as time and storage estimates, and is the mechanism for data and operations to be migrated between physical processes to keep the distributed workload balanced.  It is analogous to a virtual thread, as opposed to a physical thread.  Distributed entities are associated with `Task`s, and are responsible for packing and unpacking data for inter-process migration.  `Task`s can also share data.

 * [NotesComponentParallelMpi Mpi] The `Mpi` class is used as a wrapper for calls to MPI.
 * [NotesComponentParallelOmp Omp] The `Omp` class is used as a wrapper for calls to OpenMP.
 * [NotesComponentParallelUpc Upc] The `Upc` class is used as a wrapper for calls to Upc.

== `Parallel` class ==

=== Attributes ===

 || `double Parallel::load[][]` || ''Estimate of the load on each process group in each level'' ||
 || `Task * Parallel::tasks_` || ''list of tasks assigned to this physical process'' ||
 || `MPI_Comm * ParallelMpi::comms_[] ` || ''list of MPI communicators for each level'' ||
 || `enum level_type_[]` || ''Type of parallelization associated with each level: type_[mpi|omp|upc]'' ||

=== Functions ===

 || `Parallel::balance(int)` || ''Remap `Task`s at given level to load balance computation or memory'' ||
 || `Parallel::size(int)` || ''Number of processes/threads in the given level'' ||
 || `Parallel::rank(int)` || ''Rank of the processes/threads in the given level'' ||
 || `Parallel::comm(int)` || ''Communicator/handle for the given level'' ||

=== Usage ===

=== Parameters ===

 || `Parallel:levels` || [int , int, ... ] || E.g. `[8,32]` for 8 cores/cpu, 32 cpu's/node, etc. ||
