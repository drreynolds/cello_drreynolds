([NotesComponentMonitor Monitor] < [NotesComponents index] > [NotesComponentParameters Parameters])

[[TOC]]

= `Parallel` Component =

The `Parallel` component provides services to aid in the efficient data distribution, dynamic load balancing, and task management on hierarchical parallel platforms.  This is done using one or more parallelization languages or libraries, including MPI, OpenMP, or UPC.  The `Parallel` component keeps track of data assigned to processors in a hierarchical manner, which helps both to efficiently map data to the physical hardware, and reduce the amount of storage and communication required for load balancing.

 == Hierarchical Parallelism ==

The main data structure is a distributed tree with leaves corresponding to threads or processes, and nodes corresponding to how they are organized into higher levels, e.g. cores, sockets, nodes, cabinets, etc.  Communicators (subsets of threads, like MPI communicators, but generalized to UPC as well) are available at each level of the hierarchy to facilitate efficient communication between cores within a socket, between sockets in a node, etc.  By default, communicators link corresponding compute components in coarser-levels; for example, all processors that have rank `k` relative to their containing node form a communicator.  Communicators thus define a hypercube-like topology based on the hardware levels. To provide some flexibility to reduce hotspots in the hardware network, id's can be remapped dynamically and independently within levels to "load balance" communication.

[[Image(htdocs:mpi-latency-triton.png)]]

Each level can be assigned a different communication approach, either MPI, UPC, or OpenMP, subject to restrictions of inter-operability.  Levels can be distributed or shared memory, with no shared memory level higher than any distributed memory level.  Levels do not have to correspond directly with hardware levels.

== Related Classes ==

To implement `Parallel`, other related classes are used to share implementation responsibilities. These classes are described in separate pages.

 * [NotesComponentParallelMpi ParallelMpi] The `ParallelMpi` class is used as a wrapper for calls to MPI.
 * [NotesComponentParallelOmp ParallelOmp] The `ParallelOmp` class is used as a wrapper for calls to OpenMP.
 * [NotesComponentParallelUpc ParallelUpc] The `ParallelUpc` class is used as a wrapper for calls to Upc.

== `Parallel` class ==

=== Attributes ===

 || `ProcessGroup` || Parallel::group_[] ` || ''list of "communicators" for each level'' ||
 || `vector<enum>  || Parallel::level_type_[]` || ''Type of parallelization associated with each level: type_[mpi|omp|upc]'' ||

=== Functions ===

 || `Parallel::size(int)` || ''Number of processes/threads in the given level'' ||
 || `Parallel::rank(int)` || ''Rank of the processes/threads in the given level'' ||
 || `Parallel::num_levels()` || ''Number of communication levels'' ||
 || `Parallel::comm(int)` || ''Communicator/handle for the given level'' ||
 || || ||
 || `Parallel::get_type(i)` || ''Return the type of parallelization for the given level, e.g. mpi, upc, omp'' ||
 || `Parallel::set_type(i)` || ''Set the type of parallelization for the given level, e.g. mpi, upc, omp'' ||


=== Usage ===

=== Parameters ===

 || `Parallel:levels` || [int,int, ... ] || E.g. `[8,32]` for 8 cores/cpu, 32 cpu's/node  ||
 || `Parallel:type` || [string,string, ... ] || E.g. `["upc","upc","mpi"]` for UPC within a node and MPI between nodes||
 