([NotesComponentArray Array] < [NotesComponents index] > [NotesComponentDisk Disk])

= `Control` Component =

[[TOC]]

The `Control` component is the main scheduler in Cello, and orchestrates the distributed computations to advance the simulation in time, as well as simulation initialization and finalization.  Currently we are evaluating the use of [http://charm.cs.uiuc.edu CHARM++] in the `Control` component.  The top-level function of `Control` is `main()`.

== Patch scheduling ==

Compared to Enzo, the `Control` component does not loop through each level individually;  instead, it collapses the dependency tree to its theoretical shortest path, which is that of the finest level timesteps.  E.g. consider a 1-D problem with two levels of refinement near the center.  The parallel steps for Enzo versus Cello are shown below, with timesteps moving downward:

{{{
      Enzo: parallel levels               Cello: parallel level intervals
   +-------+---+-+-+---+-------+          +-------+---+-+-+---+-------+
   |   X   |   | | |   |   X   | 2        |   X   | X |X|X| X |   X   | 6
   +-------+---+-+-+---+-------+          +-------+---+-+-+---+-------+
   |       | X | | | X |       | 2        |       |   |X|X|   |       | 2
   +-------+---+-+-+---+-------+          +-------+---+-+-+---+-------+
   |       |   |X|X|   |       | 2        |       | X |X|X| X |       | 4
   +-------+---+-+-+---+-------+          +-------+---+-+-+---+-------+
   |       |   |X|X|   |       | 2        |       |   |X|X|   |       | 2
   +-------+---+-+-+---+-------+
   |       | X | | | X |       | 2
   +-------+---+-+-+---+-------+
   |       |   |X|X|   |       | 2
   +-------+---+-+-+---+-------+
   |       |   |X|X|   |       | 2
   
}}}

The advantage of the Cello approach is that, assuming sufficient parallelism, the finest level can be advancing continuously.  The disadvantage is that the load is inherently less balanced, since in Enzo parallel tasks are disjoint (individual levels), compared to successively inclusive (ranging between "just the finest level" to "all levels").  In the example, Enzo is perfectly balanced with 2 tasks active at each step. 
The Cello approach is never worse: with no parallelism it is the same as the Enzo approach, and with infinite parallelism it's twice as fast for this example. However, with a "practical" amount of parallelism, they will still be close, since most of the work is at the finest timestep, and that's also the limiting factor in parallelization.

Alternatively, one could run the entire simulation at the finest timestep.  If sufficient parallelism is available, a simulation would still run about as fast, and would make much higher utilization of the parallel hardware (load balancing would be much better).

{{{
         Uniform timestep
   +-------+---+-+-+---+-------+
 6 |   X   | X |X|X| X |   X   |
   +-------+---+-+-+---+-------+
 6 |   X   | X |X|X| X |   X   |
   +-------+---+-+-+---+-------+
 6 |   X   | X |X|X| X |   X   | 
   +-------+---+-+-+---+-------+
 6 |   X   | X |X|X| X |   X   |
   +-------+---+-+-+---+-------+

}}}

As an alternative approach, it may be possible to take advantage of the load imbalance of the "Cello approach", for example by scheduling I/O tasks on other nodes, or even interleaving/pipelining two independent simulations(!)  Even though independent simulations are "embarrasingly parallel" and could be implemented as such, this interleaved approach may potentially greatly increase the efficiency of using massively parallel architectures.

{{{
            Simulation 1
   +-------+---+-+-+---+-------+
 6 |   X   | X |X|X| X |   X   |         Simulation 2
   +-------+---+-+-+---+-------+ +-------+---+-+-+---+-------+
 8 |       |   |X|X|   |       | |   O   | O |O|O| O |   O   |
   +-------+---+-+-+---+-------+ +-------+---+-+-+---+-------+
 6 |       | X |X|X| X |       | |       |   |O|O|   |       |
   +-------+---+-+-+---+-------+ +-------+---+-+-+---+-------+
 6 |       |   |X|X|   |       | |       | O |O|O| O |       |
   +-------+---+-+-+---+-------+ +-------+---+-+-+---+-------+
 8 |   X   | X |X|X| X |   X   | |       |   |O|O|   |       |
  
}}}

If task scheduling is dynamic, then it may be possible to improve efficiency by ensuring that finer level tasks that are adjacent to coarse level tasks are performed first, so that coarse level tasks can begin earlier, and non-adjacent fine level tasks can run in parallel with coarser level tasks.  Since a bulk of the work is at the fine level, the main advantage of this would be more to reduce overhead time between steps, which may be significant for large numbers of processors.  The advantage of running multiple levels at once may be less advantageous, since the workload at the finest level is about the same as all other levels combined (for the example).  However, it may be used to hide latency from communication, and it may help to free up processor groups faster to improve multitasking (say) I/O with computation.

As an oversimplified summary:

 * The speed of Cello is theoretically faster than Enzo, by up to a factor of two
 * The parallel efficiency of Enzo is theoretically better than Cello
 * Uniform time-stepping is preferred when sufficient parallelism is available
 * Multiple simulations may be "interleaved" to gain higher parallel efficiency than single simulations
 * Intelligent dynamic scheduling might improve efficiency

== `Control` Supporting Classes ==

 * `Task`: A `Task` is the combination of a sequence of `Method`'s  and a `Block` (see the [NotesComponentArray Array] component).  The main operation of a `Task` is to advance the simulation one timestep on the `Block`.  Since each `Block` corresponds to a serial thread, a `Task` would be implemented as a "Chare" object in CHARM++.

([NotesComponentArray Array] < [NotesComponents index] > [NotesComponentDisk Disk])