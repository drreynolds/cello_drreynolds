Development is well underway for ``hypre-solve'', the first step in
adding AMR radiation transfer support to Enzo.  Hypre-solve is
designed to be a lightweight, flexible testing framework for setting
up linear systems defined on AMR grids for realistic test problems,
applying LLNL CASC's hypre linear solvers to the test problems, and
analyzing solver scaling, efficiency, robustness, and accuracy.
Initially, the Poisson equation will be implemented and tested, which
will be used by Enzo's gravity solver; later, support for
diffusion-like problems will be supported, which will be used by
Enzo's implicit RT solver.

Currently, hypre-solve's support for solving the parallel unigrid
Poisson equation is complete.  This functionality has already been
incorporated into Enzo by Reynolds, but was included in the
hypre-solve development to allow for more controlled testing.
Hypre-solve has also been instrumented with the LCA's performance tool
lcaperf (formerly jbPerf).  Hypre-solve support for solving the AMR
poisson equation in paralllel is expected to be complete in about a
week.  The main steps required were 1) implementing a basic
distributed AMR hierarchy datastructure and associated operations, 2)
learning to use the hypre API, 3) categorizing ``face-zones'' of the
grid patches according to their neighboring zones, and 4) setting up
the matrix nonzero graph structure and matrix element values.  We are
currently finishing up step 4.

The hypre-solve AMR hierarchy is defined using several C++ classes,
including a ``Grid'' class to represent a single grid patch, a
``Level'' class to represent all patches in a level, and a
``Hierarchy'' class to represent all levels in the AMR hierarchy.  The
hierarchy is constructed incrementally, a grid patch at a time, and
only requires knowing the grid patch extents, size, and the grid
patch's parent.  This minimalistic approach will ease the transition
of incorporating the solver in Enzo, since it will help minimize
dependencies, and provides a clean interface to Enzo's datastructures.

Learning and understanding the hypre API has been a minor challenge,
though visiting Rob Falgout and Barry Lee at LLNL at the beginning of
June was extremely helpful in clarifying some misconceptions about the
package.  While the reference guide is somewhat terse, it is
sufficient to understand the API function parameters, and the user
guide is very readable.  During our LLNL visit, Barry also pointed out
the driver program ``sstruct_fac.c'' available in the test directory
in the hypre package, which has analogous functionality to
hypre-solve, though is designed for solving smaller test problems.

Categorizing ``face-zones'' was perhaps the most tedious process.  In
hypre-solve, face-zones are categorized as ``boundary'', ``fine'',
``neighbor'', ``coarse'', or ``covered''.  During the later matrix
setup phase, only ``boundary'', ``fine'' and ``coarse'' are actually
used (``neighbor'' is handled automatically by hypre, and hypre
includes FAC solver-specific functions for the ``covered'' case).
However, the most efficient way we found to categorize ``coarse''
face-zones was to categorize everything else, so that coarse zones are
the only ones left over.

Given the face-zone categorization, the last step was to actually
create the distributed matrix in hypre.  This essentially requires two
steps: creating the nonzero structure graph, then defining the nonzero
matrix element values.  The parameters in the hypre API used to
identify elements for setting up the graph and the matrix are slightly
different: for the graph two indices identifying the row and column
are used, but for the matrix one index and an ``entry'' number are
used, where the entry number is the ``nth'' nonzero defined for the
unknown in the ``unstructured'' part.  This slight change requires the
application to store these numbers.  I hadn't anticipated this
earlier, so it required some minor backtracking in the design of
hypre-solve to store and later efficiently access these numbers.

We expect this first phase of implementing a parallel Poisson solver
for AMR problems in hypre-solve to be a large portion of the total
effort required.  After we finish implementing and testing the
distributed AMR Poisson solver in hypre-solve, there are several tasks
remaining: a) generalize matrix coefficients to support the diffusion
equation, b) run test problems to probe solver scaling, robustness,
efficiency, and discretization accuracy c) if required for accuracy,
implement a more accurate discretization scheme at grid patch
boundaries, d) if required for robustness, support a more robust
solver in hypre (e.g. BoomerAMG), e) migrate the hypre-solve code to
the Enzo-RT branch, and f) test the AMR RT algorithm by adapting to
AMR tests currently being implemented by Hayes and Reynolds for the
unigrid case.

